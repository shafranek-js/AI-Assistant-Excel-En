# AI Assistant for Excel - Session Context

## 1) Project purpose
This project is an Excel VBA assistant that:
- sends user requests to AI models,
- receives responses with a mandatory ```commands``` block,
- validates commands strictly,
- executes Excel actions automatically on the active workbook/sheet.

The app supports cloud providers, local LM Studio, and local Codex CLI mode.

## 2) Current canonical artifacts
- Latest build to open and test: `AI_Assistant_latest_dev.xlsm`
- Latest numbered build: `AI_Assistant_dev_20260213_0833_b15.xlsm`
- Editable VBA sources: `vba_unpacked_utf8/`
- Build script from editable sources: `rebuild_editable_fullforms.ps1`
- VBA unpack tool: `unpack_vba.py`

## 3) Source-of-truth files
- Core AI + command engine: `vba_unpacked_utf8/modAIHelper.bas`
- Workbook context helpers: `vba_unpacked_utf8/modExcelHelper.bas`
- Entry points and Excel menu button: `vba_unpacked_utf8/modMain.bas`
- Chat form logic: `vba_unpacked_utf8/frmChat.frm`
- Settings form logic: `vba_unpacked_utf8/frmSettings.frm`
- Build/rebuild pipeline: `rebuild_editable_fullforms.ps1`

## 4) High-level architecture
1. User interacts with `frmChat`.
2. `frmChat` builds context via `GetWorkbookContext()` and optional `GetSelectedData()`.
3. Request is sent to:
- `SendToAI(...)` for cloud/direct/Codex CLI routes.
- `SendToLocalAI(...)` for LM Studio route.
4. Response text is parsed by `ExtractCommands(...)`.
5. Commands are validated by `ValidateCommandStrict(...)`.
6. Valid commands are executed by `ExecuteSingleCommand(...)`.
7. Result summary is appended to chat.

## 5) Model/provider routing (current)
UI model list in `frmChat`:
- `Gemini 3 Flash`
- `GPT-5.2 (OpenRouter)`
- `GPT-5.2 (Direct OpenAI)`
- `GPT-5.2 Codex (Direct)`
- `Codex CLI (ChatGPT Plus)`
- `Gemini 3 Pro`
- `Claude Sonnet 4.5`
- `DeepSeek`

Internal model keys used by `SendToAI(...)`:
- `deepseek` -> `https://api.deepseek.com/chat/completions`
- `gpt-direct` -> `https://api.openai.com/v1/chat/completions` model `gpt-5.2`
- `gpt-codex-direct` -> `https://api.openai.com/v1/chat/completions` model `gpt-5.2-codex`
- `codex-cli` -> local `codex exec` (no API key in app)
- `claude`, `gpt`, `gemini`, `gemini-flash` -> `https://openrouter.ai/api/v1/chat/completions`

Model constants are in `modAIHelper.bas` top section.

## 6) Forms and UI state
### `frmChat`
- Purpose: main conversation and execution flow.
- Has `Cloud`/`Local` mode toggle.
- `Preview Commands` checkbox controls confirmation before command execution.
- `Include Data` checkbox appends selected range data to context.
- Supports image attach (`btnAttach`) for non-DeepSeek cloud routes and Codex CLI route.

### `frmSettings`
- Current runtime size: width `500`, height `340`.
- Fields:
- `DeepSeek API key`
- `OpenRouter API key`
- `OpenAI API key`
- `LM Studio IP`
- `LM Studio Port`
- `LM Studio model`
- `Response language` values:
- `English`
- `Russian`
- `Ukrainian`
- `Czech`
- `Spanish`
- `German`

## 7) Settings and key storage
Storage location:
- Registry base: `HKEY_CURRENT_USER\Software\ExcelAIAssistant\`

API key values:
- `DeepSeekKey`
- `OpenRouterKey`
- `OpenAIKey`

LM Studio/settings values:
- `LMStudio_IP`
- `LMStudio_Port`
- `LMStudio_Model`
- `LMStudio_Enabled`
- `LMStudio_PreviewCommands`
- `LMStudio_ResponseLanguage`

Important:
- Keys are currently stored as plain `REG_SZ` strings.
- This is functional but not secure-at-rest (candidate future hardening item).

## 8) Prompt and language behavior
System prompt is generated by `BuildSystemPrompt(...)` in `modAIHelper.bas`.
It includes:
- strict response format requirement,
- full command catalog,
- rule to use exact addresses from context,
- formula localization note,
- language directive: `Answer in <ResponseLanguage>`.

Default response language:
- `English` if no stored setting.

## 9) Command processing and safety
Pipeline:
1. `ExtractCommands(...)` pulls content from the fenced `commands` code block.
2. `ExecuteCommands(...)` iterates line-by-line.
3. `ValidateCommandStrict(...)` checks action name, arg count, range/address syntax, types, enums, and constraints.
4. `ExecuteSingleCommand(...)` applies Excel operations.

Execution summary format:
- `[Commands executed: X, rejected: Y, failed: Z]`
- optional details for first few failures/rejections.

Supported command surface:
- Large command set across cells/formatting/rows-columns/sort-filter/charts/pivots/sheets/named ranges/conditional formatting/validation/comments/hyperlinks/protection/view/print/images/forms/special tools.
- Source of truth for command catalog text: `BuildSystemPrompt(...)`.
- Source of truth for actual runtime behavior: `ExecuteSingleCommand(...)` and `ValidateCommandStrict(...)`.

## 10) Reliability features already implemented
- HTTP retry with backoff for API/local HTTP.
- Retries on `429` and `5xx`.
- Retries on transient network errors.
- Supports `Retry-After` header.
- Better error parsing.
- Special handling for `insufficient_quota`.
- Extraction of `message/error/detail`.
- Direct OpenAI throttling mitigation.
- Lower token cap for direct routes.
- Context clamping for direct routes.
- Preview-before-execute toggle in chat (`PreviewCommands` setting).
- Strict command validation before execution.

## 11) Codex CLI integration (ChatGPT Plus path)
Route key: `codex-cli`.

Behavior:
- `SendToAI(...)` dispatches to `SendToCodexCLI(...)`.
- Uses local shell command.
- `codex exec --skip-git-repo-check --color never --output-last-message <file> -C <workdir> - < <prompt>`
- Optional image is passed via `--image`.
- Prompt and outputs are stored temporarily under:
- `%TEMP%\ExcelAIAssistantCodex`
- Temp files are cleaned after run.
- Timeout constant:
- `CODEX_CLI_TIMEOUT_SECONDS = 240`

Common failure mode:
- If CLI is not logged in, app returns:
- `ERROR: Codex CLI is not logged in. Run 'codex login' in terminal and try again.`

## 12) Build and rebuild workflow
Main build command:
```powershell
.\rebuild_editable_fullforms.ps1 -InputDir .\vba_unpacked_utf8 -Track dev
```

What the build script does:
1. Opens Excel COM.
2. Creates a new macro-enabled workbook.
3. Injects modules from `.bas/.cls`.
4. Recreates forms via Designer controls (not via prebuilt `.frx/.bin`).
5. Injects form code bodies from `.frm` files (attributes stripped).
6. Saves workbook as `.xlsm`.
7. Updates alias file: `AI_Assistant_latest_<track>.xlsm`.

Naming scheme:
- `AI_Assistant_<track>_yyyyMMdd_HHmm_bNN.xlsm`
- Example: `AI_Assistant_dev_20260213_0833_b15.xlsm`

## 13) VBA unpack workflow
Extract VBA from `vbaProject.bin`:
```powershell
python .\unpack_vba.py vbaProject.bin --out vba_unpacked_utf8 --encoding utf-8-sig
```

Tool details:
- `unpack_vba.py` parses OLE streams, decompresses VBA containers, detects project code page, and writes source modules.
- Useful for recovering source from existing `.xlsm/.xlam` binaries.

## 14) Entry points and user commands
From `modMain.bas`:
- `ShowAIAssistant` -> opens `frmChat` modeless.
- `ShowSettings` -> opens `frmSettings` modal.
- `Auto_Open` / `Auto_Close` -> create/remove `AI Assistant` menu button on worksheet menu bar.
- `QuickAnalyze` -> quick cloud analysis flow (fallback between configured keys).

## 15) Known operational prerequisites
- Excel desktop with VBA enabled.
- Trust Center setting usually required for build script and VBProject automation.
- `Trust access to the VBA project object model`.
- Network access for cloud providers.
- LM Studio running locally for local mode.
- Codex CLI installed and logged in for `Codex CLI (ChatGPT Plus)` route.

## 16) Current roadmap status snapshot
Based on implemented code, these roadmap items are already present:
- Response language setting in Settings form (extended multilingual set).
- Preview commands before execute toggle.
- Strict command validation before execution.
- Retry/backoff for API/network failures.
- Direct OpenAI route and direct Codex route.
- Local Codex CLI route (plus-plan usage path).

Open strategic items (from `IMPROVEMENT.MD`) still relevant:
- Dry run mode.
- AI action log sheet.
- Safe mode for risky commands.
- Secure key storage (DPAPI/Credential Manager wrapper).
- Refactor monolithic `modAIHelper` into focused modules.
- Smoke tests and deployment signing process.

## 17) Known fixed issues
Date: February 13, 2026.

1. Codex CLI route caused Excel/add-in freeze (window stuck at `Codex CLI...`).
- Root cause: blocking/non-robust process I/O handling around `WScript.Shell.Exec` for long-running `codex exec`.
- Fix: `RunCommandCapture(...)` moved to file-redirection based execution (`exec_out_*.txt`, `exec_err_*.txt`) with polling and non-blocking wait (`SpinWaitSeconds` + `DoEvents`), no direct live `StdOut/StdErr` pipe reads.
- Additional hardening: Codex timeout reduced to `90` seconds.

2. `codex exec` compatibility error `unexpected argument '--no-alt-screen'`.
- Root cause: local Codex CLI version does not support that flag for `exec`.
- Fix: removed unsupported flag from command template.

3. Exit `-1073741510` during Codex execution.
- Root cause: interrupted process (console closed / cancel signal).
- Fix: explicit handling and user-facing error message for interrupted Codex process.

4. `ActiveX component can't create object` on some add-in environments.
- Root cause: unavailable COM objects (e.g., `WScript.Shell` / `ADODB.Stream` / specific HTTP classes).
- Fix: fallback paths added:
- command execution fallback (`RunCommandCaptureShellFallback`),
- file I/O ANSI fallback when UTF-8 stream object is unavailable,
- consolidated HTTP object creation via `CreateHttpClient()` in LM Studio checks.

5. Local mode auto-selection false positive.
- Root cause: previous check accepted default IP/Port strings as “configured” even when LM Studio was not reachable.
- Fix: `HasLocalModel()` now depends on endpoint availability check.

## 18) Quick restart checklist for a new CLI session
1. Open `CONTEXT.MD`.
2. Treat `vba_unpacked_utf8/` as editable source-of-truth.
3. Modify modules/forms there.
4. Rebuild with `rebuild_editable_fullforms.ps1`.
5. Test in `AI_Assistant_latest_dev.xlsm`.
6. If issue involves encoding/bin mismatch, verify by extracting `xl/vbaProject.bin` and re-running `unpack_vba.py`.
